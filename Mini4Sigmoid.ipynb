{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Get data"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-07T09:33:01.330300300Z",
          "start_time": "2023-12-07T09:33:01.315660700Z"
        },
        "id": "O_8iqH4aJJEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "checkpoints = '/content/drive/MyDrive/colab_files/imagenet64/'\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)"
      ],
      "metadata": {
        "id": "CIwlctdNC_OL",
        "is_executing": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8131d71a-02f5-4e6d-8b3c-e9b2c0be55a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "u_umsKSKxmT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "!pip install unrar\n",
        "if not os.path.exists('imagenet64'):\n",
        "  print(\"Copying to local runtime...\")\n",
        "  shutil.copy(checkpoints + 'DATA.rar', './DATA.rar')\n",
        "  print(\"Uncompressing...\")\n",
        "  !unrar x DATA.rar\n",
        "print(\"Data ready!\")"
      ],
      "metadata": {
        "id": "ESBGUvl3DIwh",
        "is_executing": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dfb447-5c98-4f95-9671-c8c8bed49828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unrar\n",
            "  Downloading unrar-0.4-py3-none-any.whl (25 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53W3ULah7okz",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ],
      "metadata": {
        "id": "4lFdjNKBjj1M",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Origional Algorithm With out any changing/ data augrumenting etc"
      ],
      "metadata": {
        "id": "rmM7utNPcQT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet model\n",
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "                        padding= 'valid', activation= 'sigmoid',\n",
        "                        input_shape= input_shape,\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "                        padding= 'same', activation= 'sigmoid',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'sigmoid',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'sigmoid',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'sigmoid',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation= 'sigmoid'))\n",
        "        self.add(Dense(4096, activation= 'sigmoid'))\n",
        "        self.add(Dense(1000, activation= 'sigmoid'))\n",
        "        self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TgQdaTEhx4j3",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 20\n",
        "model = AlexNet((227, 227, 3), num_classes)"
      ],
      "metadata": {
        "id": "OwhWrBbtyOcb",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "image_height = 227\n",
        "image_width = 227\n",
        "train_dir = \"/content/train\"\n",
        "valid_dir = \"/content/val\"\n",
        "model_dir = \"/my_model.h5\""
      ],
      "metadata": {
        "id": "155vZtbFzRb_",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale=1./255 ,\n",
        "                  rotation_range=10,\n",
        "                  width_shift_range=0.1,\n",
        "                  height_shift_range=0.1,\n",
        "                  shear_range=0.1,\n",
        "                  zoom_range=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                          target_size=(image_height, image_width),\n",
        "                          color_mode=\"rgb\",\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          seed=1,\n",
        "                          shuffle=True,\n",
        "                          class_mode=\"categorical\")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
        "                        target_size=(image_height, image_width),\n",
        "                        color_mode=\"rgb\",\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        seed=7,\n",
        "                        shuffle=True,\n",
        "                        class_mode=\"categorical\"\n",
        "                        )\n",
        "train_num = train_generator.samples\n",
        "valid_num = valid_generator.samples"
      ],
      "metadata": {
        "id": "7Qz8qmjh0VHy",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run test"
      ],
      "metadata": {
        "id": "RkkWqtVLp0pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wcnwWgZC2Tcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "callback_list = [tensorboard_callback]\n",
        "\n",
        "# start training\n",
        "model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=train_num // BATCH_SIZE,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_num // BATCH_SIZE,\n",
        "                    callbacks=callback_list,\n",
        "                    verbose=0)\n",
        "model.summary()\n",
        "\n",
        "# save the whole model\n",
        "model.save(model_dir)"
      ],
      "metadata": {
        "id": "STaYMcYh0jiM",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy: top 1 error and top 5 error"
      ],
      "metadata": {
        "id": "GfVayabi74cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = os.listdir()\n",
        "\n",
        "x_valid = []\n",
        "label_batch  = []\n",
        "pop = 0\n",
        "t1=0\n",
        "t3=0\n",
        "k=0\n",
        "\n",
        "for x_valid_b, y_valid_b in valid_generator:\n",
        "  if(k > 1000/128):break\n",
        "  k+=1\n",
        "  prediction_values = model.predict(x_valid_b,batch_size=x_valid_b.shape[0])\n",
        "  for i in range(len(prediction_values)):\n",
        "    pop +=1\n",
        "    #print(type(prediction_values[i]))\n",
        "    answer = np.where(y_valid_b[i] == 1)[0][0]\n",
        "    sorted_indices = np.argsort(prediction_values[i])[::-1]\n",
        "    top_3 = sorted_indices[:3]\n",
        "\n",
        "    top_one = sorted_indices[:1]\n",
        "    if answer in top_3:t3 += 1\n",
        "    if top_one == answer: t1 +=1\n",
        "\n",
        "\n",
        "print(pop)\n",
        "\n",
        "\n",
        "print(\"top 1 accuracy = %5.3f\" %(t1/pop) )\n",
        "print(\"top 5 accuracy = %5.3f\" %(t3/pop) )"
      ],
      "metadata": {
        "id": "Zheamehr2AOw",
        "is_executing": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}