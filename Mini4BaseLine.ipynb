{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Get data"
      ],
      "metadata": {
        "id": "Z19puIwVDRkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "checkpoints = '/content/drive/MyDrive/colab_files/imagenet64/'\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIwlctdNC_OL",
        "outputId": "662bd6fd-64b9-4673-bbcc-82ec235754e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "if not os.path.exists('imagenet64'):\n",
        "  if not os.path.exists(checkpoints + 'imagenet64.tar'):\n",
        "    print(\"Downloading archive...\")\n",
        "    os.chdir(checkpoints)\n",
        "    !wget https://pjreddie.com/media/files/imagenet64.tar\n",
        "    os.chdir('/content/')\n",
        "  print(\"Copying to local runtime...\")\n",
        "  shutil.copy(checkpoints + 'imagenet64.tar', './imagenet64.tar')\n",
        "  print(\"Uncompressing...\")\n",
        "  !tar -xf imagenet64.tar\n",
        "print(\"Data ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBGUvl3DIwh",
        "outputId": "b4a2adc9-6b82-4db4-8e07-c2a311c49475"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53W3ULah7okz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ],
      "metadata": {
        "id": "4lFdjNKBjj1M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Origional Algorithm With out any changing/ data augrumenting etc"
      ],
      "metadata": {
        "id": "rmM7utNPcQT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet model\n",
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "                        padding= 'valid', activation= 'relu',\n",
        "                        input_shape= input_shape,\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(1000, activation= 'relu'))\n",
        "        self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TgQdaTEhx4j3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 1000\n",
        "model = AlexNet((227, 227, 3), num_classes)"
      ],
      "metadata": {
        "id": "OwhWrBbtyOcb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "image_height = 227\n",
        "image_width = 227\n",
        "train_dir = \"/content/imagenet64/train\"\n",
        "valid_dir = \"/content/imagenet64/val\"\n",
        "model_dir = \"/my_model.h5\""
      ],
      "metadata": {
        "id": "155vZtbFzRb_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale=1,\n",
        "                  rotation_range=0,\n",
        "                  width_shift_range=0,\n",
        "                  height_shift_range=0,\n",
        "                  shear_range=0,\n",
        "                  zoom_range=0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                          target_size=(image_height, image_width),\n",
        "                          color_mode=\"rgb\",\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          seed=1,\n",
        "                          shuffle=True,\n",
        "                          class_mode=\"categorical\")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
        "                        target_size=(image_height, image_width),\n",
        "                        color_mode=\"rgb\",\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        seed=7,\n",
        "                        shuffle=True,\n",
        "                        class_mode=\"categorical\"\n",
        "                        )\n",
        "train_num = train_generator.samples\n",
        "valid_num = valid_generator.samples"
      ],
      "metadata": {
        "id": "7Qz8qmjh0VHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run test"
      ],
      "metadata": {
        "id": "RkkWqtVLp0pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wcnwWgZC2Tcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "callback_list = [tensorboard_callback]\n",
        "\n",
        "# start training\n",
        "model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=train_num // BATCH_SIZE,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_num // BATCH_SIZE,\n",
        "                    callbacks=callback_list,\n",
        "                    verbose=0)\n",
        "model.summary()\n",
        "\n",
        "# save the whole model\n",
        "model.save(model_dir)"
      ],
      "metadata": {
        "id": "STaYMcYh0jiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy: top 1 error and top 5 error"
      ],
      "metadata": {
        "id": "GfVayabi74cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = allClasses\n",
        "\n",
        "x_valid = []\n",
        "label_batch  = []\n",
        "pop = 0\n",
        "t1=0\n",
        "t5=0\n",
        "\n",
        "for x_valid_b, y_valid_b in valid_generator:\n",
        "  prediction_values = model.predict_proba(x_valid)\n",
        "  for i in range(len(prediction_values)):\n",
        "    pop +=1\n",
        "    answer = class_names.index(y_valid_b[i])\n",
        "    top_five = sorted(range(len(prediction_values)), key=lambda i: prediction_values[i], reverse=True)[:5]\n",
        "    top_one = prediction_values.index(max(prediction_values))\n",
        "    if answer in top_five:t5 += 1\n",
        "    if top_one == answer: t1 +=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"top 1 accuracy = %5.3f\" %(t1/pop) )\n",
        "print(\"top 5 accuracy = %5.3f\" %(t5/pop) )"
      ],
      "metadata": {
        "id": "Zheamehr2AOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}